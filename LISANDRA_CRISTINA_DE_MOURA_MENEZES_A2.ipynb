{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NpMi6bG9z1t"
      },
      "source": [
        "Faça o upload de um arquivo .zip com os seus dados e use o comando abaixo após a finalização do upload para a extração do conteúdo do arquivo no colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smgD-6OS-KuL"
      },
      "source": [
        "Implemente as funções a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "__8dnSXJ_YtC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\asyncio\\events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\moura\\AppData\\Local\\Temp\\ipykernel_21788\\21326102.py\", line 6, in <module>\n",
            "    from torchvision.io import read_image\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\models\\__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\models\\convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\ops\\__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\ops\\poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\ops\\roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
            "    torch.manual_seed = disable(torch.manual_seed)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
            "    return DisableContext()(fn)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
            "    (filename is None or trace_rules.check(fn))\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
            "    return check_verbose(obj, is_inlined_call).skipped\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
            "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
            "    rule = get_torch_obj_rule_map().get(obj, None)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
            "    obj = load_object(k)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
            "    val = _load_obj_from_str(x[0])\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
            "    return getattr(importlib.import_module(module), obj_name)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
            "    values=torch.randn(3, 3, device=\"meta\"),\n",
            "c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  values=torch.randn(3, 3, device=\"meta\"),\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0asP2qsKXuBN"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CarSimDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path) \n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)  \n",
        "        \n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        \n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crie as variáveis a seguir a partir da classe implementada acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Ajuste nas transformações para assegurar que o tensor seja convertido para float, normalizado e com aumento de dados aplicado\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  \n",
        "    transforms.RandomRotation(degrees=5),  \n",
        "    transforms.ColorJitter(brightness=0.2), \n",
        "    transforms.RandomHorizontalFlip(),  \n",
        "    transforms.ConvertImageDtype(torch.float), \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
        "])\n",
        "\n",
        "# Transformação dos rótulos (normalizando os valores de ângulo, se aplicável)\n",
        "def normalize_labels(label):\n",
        "    max_angle = 25  \n",
        "    return label / max_angle\n",
        "\n",
        "# Dataset de treino com transformações atualizadas\n",
        "train_dataset = CarSimDataset(\n",
        "    annotations_file='C:\\\\Users\\\\moura\\\\simulator\\\\dados_2\\\\driving_log.csv',\n",
        "    img_dir='C:\\\\Users\\\\moura\\\\simulator\\\\dados_2\\\\IMG',\n",
        "    transform=transform,\n",
        "    target_transform=normalize_labels \n",
        ")\n",
        "\n",
        "# Dataset de teste\n",
        "test_dataset = CarSimDataset(\n",
        "    annotations_file='C:\\\\Users\\\\moura\\\\simulator\\\\dados_2\\\\driving_log.csv',\n",
        "    img_dir='C:\\\\Users\\\\moura\\\\simulator\\\\dados_2\\\\IMG',\n",
        "    transform=transform,\n",
        "    target_transform=normalize_labels\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.CarSimDataset at 0x1e4266e68d0>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXDLTbuqESux"
      },
      "source": [
        "O código abaixo será utilizado para treinar o modelo com o seu dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xwd083wA_rrD"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5VJYlF1KSi44",
        "outputId": "d4f4b5c6-81ff-4871-86ae-1ac30dd54937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.float32\n"
          ]
        }
      ],
      "source": [
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROBTIl6pAESA",
        "outputId": "6e9f988b-ea0c-47ad-91de-0bef2b30448a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=2352, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28*3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits.squeeze()\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PJxdeuCBBRc-"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0Cw8XfLNBY97"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b-T_bjFhBnOX"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "8x4aJZpNBqAt",
        "outputId": "3387f2ac-9b26-4b92-abf9-5738617078b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.008030  [   64/ 3434]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[9], line 11\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m      9\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     10\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 11\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     12\u001b[0m test_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n\u001b[0;32m     13\u001b[0m correct \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m size\n",
            "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "5AaRBZ1gDxUP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model_0.2.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvtnIBFlD35c"
      },
      "source": [
        "Faça o download do seu modelo após o treinamento, caso queira testá-lo no simulador.\n",
        "\n",
        "O código a seguir demonstra como o modelo será usado para inferência no simulador. Caso seja necessário, altere a função *preprocess*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVqjjnUOGc8F"
      },
      "outputs": [],
      "source": [
        "def preprocess(x):\n",
        "    # TODO: se necessário, alterar função\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LLWerSXFjRR"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model_0.1.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_0.1.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32mc:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_0.1.pth'"
          ]
        }
      ],
      "source": [
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAI2oGcAGqsz"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m preprocess(x)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "x = test_data[0][0]\n",
        "with torch.no_grad():\n",
        "    x = preprocess(x)\n",
        "    x = x.to(device)\n",
        "    pred = model(x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
